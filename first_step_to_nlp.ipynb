{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "import keras\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ô¶Ô∏è I wish you to stay healthy. Your character,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les bases de l'algorithmique b Darija vos rema...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corona restrictions causing terrible financial...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üì£üì£AMAZON recrute des conseillers clients √† Dom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great illustration....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great to see companies across Canada stepping ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Le Maroc dont je suis si fier...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hashtag#ÿπÿßÿ¨ŸÑ : ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸäŸÜ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I just published the fourth and last blog post...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The pain you feel today is the strength you fe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  label\n",
       "0  ‚ô¶Ô∏è I wish you to stay healthy. Your character,...      0\n",
       "1  Les bases de l'algorithmique b Darija vos rema...      0\n",
       "2  Corona restrictions causing terrible financial...      0\n",
       "3  üì£üì£AMAZON recrute des conseillers clients √† Dom...      1\n",
       "4                             Great illustration....      0\n",
       "5  Great to see companies across Canada stepping ...      0\n",
       "6                   Le Maroc dont je suis si fier...      0\n",
       "7  hashtag#ÿπÿßÿ¨ŸÑ : ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸäŸÜ ...      0\n",
       "8  I just published the fourth and last blog post...      0\n",
       "9  The pain you feel today is the strength you fe...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data\n",
    "data =pd.read_csv('data.csv')\n",
    "data = data[['description','label']]\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data20 = data[data.label == 1][[\"description\"]].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Stopwords = {''}\n",
    "Stopwords_fr=set(stopwords.words('french'))\n",
    "Stopwords_eng = set(stopwords.words('english'))\n",
    "add_stop_words = \"all almost also any because cause could do does done don't end for never see soon sorry than ourselves hers between yourself ut again there about once during out very having with they own an be some for do its yours such into of most itself other off is s am for who as from him each the themselves until below are we these your his through don nor me were her more himself this down should our their while above both up to ours had she all no when at any before them same and been have in will on does yourselves then that because what over why so can did not now under he you herself has just where too only myself which those i after few whom t being if theirs my against a by doing it how further was here than a √† √¢ abord afin ah ai aie ainsi allaient allo all√¥ allons apr√®s assez attendu au aucun aucune aujourd aujourd'hui auquel aura auront aussi autre autres aux auxquelles auxquels avaient avais avait avant avec avoir ayant b bah beaucoup bien bigre boum bravo brrr c √ßa car ce ceci cela celle celle-ci celle-l√† celles celles-ci celles-l√† celui celui-ci celui-l√† cent cependant certain certaine certaines certains certes ces cet cette ceux ceux-ci ceux-l√† chacun chaque cher ch√®re ch√®res chers chez chiche chut ci cinq cinquantaine cinquante cinquanti√®me cinqui√®me clac clic combien comme comment compris concernant contre couic crac d da dans de debout dedans dehors del√† depuis derri√®re des d√®s d√©sormais desquelles desquels dessous dessus deux deuxi√®me deuxi√®mement devant devers devra diff√©rent diff√©rente diff√©rentes diff√©rents dire divers diverse diverses dix dix-huit dixi√®me dix-neuf dix-sept doit doivent donc dont douze douzi√®me dring du duquel durant e effet eh elle elle-m√™me elles elles-m√™mes en encore entre envers environ es √®s est et etant √©taient √©tais √©tait √©tant etc √©t√© etre √™tre eu euh eux eux-m√™mes except√© f fa√ßon fais faisaient faisant fait feront fi flac floc font g gens h ha h√© hein h√©las hem hep hi ho hol√† hop hormis hors hou houp hue hui huit huiti√®me hum hurrah i il ils importe j je jusqu jusque k l la l√† laquelle las le lequel les l√®s lesquelles lesquels leur leurs longtemps lorsque lui lui-m√™me m ma maint mais malgr√© me m√™me m√™mes merci mes mien mienne miennes miens mille mince moi moi-m√™me moins mon moyennant n na ne n√©anmoins neuf neuvi√®me ni nombreuses nombreux non nos notre n√¥tre n√¥tres nous nous-m√™mes nul o o| √¥ oh oh√© ol√© oll√© on ont onze onzi√®me ore ou o√π ouf ouias oust ouste outre p paf pan par parmi partant particulier particuli√®re particuli√®rement pas pass√© pendant personne peu peut peuvent peux pff pfft pfut pif plein plouf plus plusieurs plut√¥t pouah pour pourquoi premier premi√®re premi√®rement pr√®s proche psitt puisque q qu quand quant quanta quant-√†-soi quarante quatorze quatre quatre-vingt quatri√®me quatri√®mement que quel quelconque quelle quelles quelque quelques quelqu'un quels qui quiconque quinze quoi quoique r revoici revoil√† rien s sa sacrebleu sans sapristi sauf se seize selon sept septi√®me sera seront ses si sien sienne siennes siens sinon six sixi√®me soi soi-m√™me soit soixante son sont sous stop suis suivant sur surtout t ta tac tant te t√© tel telle tellement telles tels tenant tes tic tien tienne tiennes tiens toc toi toi-m√™me ton touchant toujours tous tout toute toutes treize trente tr√®s trois troisi√®me troisi√®mement trop tsoin tsouin tu u un une unes uns v va vais vas v√© vers via vif vifs vingt vivat vive vives vlan voici voil√† vont vos votre v√¥tre v√¥tres vous vous-m√™mes vu w x y z zut\"\n",
    "add_stop_words = add_stop_words.split()\n",
    "Stopwords.update(add_stop_words)\n",
    "Stopwords.update(Stopwords_fr)\n",
    "Stopwords.update(Stopwords_eng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def stemSentence(sentence):\n",
    "    token_words=word_tokenize(str(sentence))\n",
    "    token_words\n",
    "    porter = PorterStemmer()\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>new_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ô¶Ô∏è I wish you to stay healthy. Your character,...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ô¶Ô∏è I wish you to stay healthi . your charact ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les bases de l'algorithmique b Darija vos rema...</td>\n",
       "      <td>0</td>\n",
       "      <td>le base de l'algorithmiqu b darija vo remarqu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corona restrictions causing terrible financial...</td>\n",
       "      <td>0</td>\n",
       "      <td>corona restrict caus terribl financi stress to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üì£üì£AMAZON recrute des conseillers clients √† Dom...</td>\n",
       "      <td>1</td>\n",
       "      <td>üì£üì£amazon recrut de conseil client √† domicil .üßë...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great illustration....</td>\n",
       "      <td>0</td>\n",
       "      <td>great illustr ... .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  label  \\\n",
       "0  ‚ô¶Ô∏è I wish you to stay healthy. Your character,...      0   \n",
       "1  Les bases de l'algorithmique b Darija vos rema...      0   \n",
       "2  Corona restrictions causing terrible financial...      0   \n",
       "3  üì£üì£AMAZON recrute des conseillers clients √† Dom...      1   \n",
       "4                             Great illustration....      0   \n",
       "\n",
       "                                     new_description  \n",
       "0  ‚ô¶Ô∏è I wish you to stay healthi . your charact ,...  \n",
       "1     le base de l'algorithmiqu b darija vo remarqu   \n",
       "2  corona restrict caus terribl financi stress to...  \n",
       "3  üì£üì£amazon recrut de conseil client √† domicil .üßë...  \n",
       "4                               great illustr ... .   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['new_description']= data['description'].apply(stemSentence)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation #+\"‚Äô¬∂‚Ä¢@¬∞¬©¬Æ‚Ñ¢\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct(text):\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    translator = str.maketrans(punctuations,\" \"*len(punctuations))\n",
    "    s = text.translate(translator)\n",
    "    \n",
    "    res = ''.join([i for i in s if not i.isdigit()])\n",
    "    \n",
    "    wordtokens = word_tokenize(res)\n",
    "    \n",
    "    return  ' '.join([w for w in wordtokens if not w in Stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_description2']=data['new_description'].apply(funct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(data['new_description2']).split()).value_counts()[:3]\n",
    "freq\n",
    "data['new_description2'] = data['new_description2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "      <th>new_description</th>\n",
       "      <th>new_description2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‚ô¶Ô∏è I wish you to stay healthy. Your character,...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ô¶Ô∏è I wish you to stay healthi . your charact ,...</td>\n",
       "      <td>‚ô¶Ô∏è wish stay healthi charact strength kind rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les bases de l'algorithmique b Darija vos rema...</td>\n",
       "      <td>0</td>\n",
       "      <td>le base de l'algorithmiqu b darija vo remarqu</td>\n",
       "      <td>base algorithmiqu darija vo remarqu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corona restrictions causing terrible financial...</td>\n",
       "      <td>0</td>\n",
       "      <td>corona restrict caus terribl financi stress to...</td>\n",
       "      <td>corona restrict caus terribl financi stress po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üì£üì£AMAZON recrute des conseillers clients √† Dom...</td>\n",
       "      <td>1</td>\n",
       "      <td>üì£üì£amazon recrut de conseil client √† domicil .üßë...</td>\n",
       "      <td>üì£üì£amazon recrut conseil client domicil üßë‚Äçüíªproc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great illustration....</td>\n",
       "      <td>0</td>\n",
       "      <td>great illustr ... .</td>\n",
       "      <td>great illustr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Great to see companies across Canada stepping ...</td>\n",
       "      <td>0</td>\n",
       "      <td>great to see compani across canada step up to ...</td>\n",
       "      <td>great compani across canada step help fight co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Le Maroc dont je suis si fier...</td>\n",
       "      <td>0</td>\n",
       "      <td>Le maroc dont je sui si fier ...</td>\n",
       "      <td>maroc sui fier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hashtag#ÿπÿßÿ¨ŸÑ : ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸäŸÜ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>hashtag # ÿπÿßÿ¨ŸÑ : ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸä...</td>\n",
       "      <td>ÿπÿßÿ¨ŸÑ ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸäŸÜ ÿ£ÿ®ÿ≥ÿ∑ Ÿàÿ≥ÿßÿ¶ŸÑ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I just published the fourth and last blog post...</td>\n",
       "      <td>0</td>\n",
       "      <td>I just publish the fourth and last blog post a...</td>\n",
       "      <td>publish fourth last blog post java featur thi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The pain you feel today is the strength you fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>the pain you feel today is the strength you fe...</td>\n",
       "      <td>pain feel today strength feel tomorrowhashtag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ÿ£ŸàŸÑ ÿ¨Ÿáÿßÿ≤ ŸÖÿ≥ÿßÿπÿØÿ© ŸÑŸÑÿ™ŸÜŸÅÿ≥ ŸÖÿ∫ÿ±ÿ®Ÿä ŸÖÿ≠ŸÑŸä ÿßŸÑÿµŸÜÿπ. ŸÜÿ≠ÿ™ÿßÿ¨...</td>\n",
       "      <td>0</td>\n",
       "      <td>ÿ£ŸàŸÑ ÿ¨Ÿáÿßÿ≤ ŸÖÿ≥ÿßÿπÿØÿ© ŸÑŸÑÿ™ŸÜŸÅÿ≥ ŸÖÿ∫ÿ±ÿ®Ÿä ŸÖÿ≠ŸÑŸä ÿßŸÑÿµŸÜÿπ . ŸÜÿ≠ÿ™ÿß...</td>\n",
       "      <td>ÿ£ŸàŸÑ ÿ¨Ÿáÿßÿ≤ ŸÖÿ≥ÿßÿπÿØÿ© ŸÑŸÑÿ™ŸÜŸÅÿ≥ ŸÖÿ∫ÿ±ÿ®Ÿä ŸÖÿ≠ŸÑŸä ÿßŸÑÿµŸÜÿπ ŸÜÿ≠ÿ™ÿßÿ¨ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Are you at Home practicing social distancing t...</td>\n",
       "      <td>0</td>\n",
       "      <td>are you at home practic social distanc to figh...</td>\n",
       "      <td>home practic social distanc fight spread covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ce virus a d√©voil√© une chose tr√®s importante p...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ce viru a d√©voil√© une chose tr√® important pa a...</td>\n",
       "      <td>viru d√©voil√© chose tr√® important pa gen mai go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tout le monde est au courant sur le programme ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tout le mond est au courant sur le programm de...</td>\n",
       "      <td>mond courant programm coursera covid alor cr√©e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kamal EL FATIHI hashtag#Kudos I really appreci...</td>\n",
       "      <td>0</td>\n",
       "      <td>kamal EL fatihi hashtag # kudo I realli apprec...</td>\n",
       "      <td>kamal el fatihi kudo realli appreci goingabove...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description  label  \\\n",
       "0   ‚ô¶Ô∏è I wish you to stay healthy. Your character,...      0   \n",
       "1   Les bases de l'algorithmique b Darija vos rema...      0   \n",
       "2   Corona restrictions causing terrible financial...      0   \n",
       "3   üì£üì£AMAZON recrute des conseillers clients √† Dom...      1   \n",
       "4                              Great illustration....      0   \n",
       "5   Great to see companies across Canada stepping ...      0   \n",
       "6                    Le Maroc dont je suis si fier...      0   \n",
       "7   hashtag#ÿπÿßÿ¨ŸÑ : ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸäŸÜ ...      0   \n",
       "8   I just published the fourth and last blog post...      0   \n",
       "9   The pain you feel today is the strength you fe...      0   \n",
       "10  ÿ£ŸàŸÑ ÿ¨Ÿáÿßÿ≤ ŸÖÿ≥ÿßÿπÿØÿ© ŸÑŸÑÿ™ŸÜŸÅÿ≥ ŸÖÿ∫ÿ±ÿ®Ÿä ŸÖÿ≠ŸÑŸä ÿßŸÑÿµŸÜÿπ. ŸÜÿ≠ÿ™ÿßÿ¨...      0   \n",
       "11  Are you at Home practicing social distancing t...      0   \n",
       "12  Ce virus a d√©voil√© une chose tr√®s importante p...      0   \n",
       "13  tout le monde est au courant sur le programme ...      0   \n",
       "14  Kamal EL FATIHI hashtag#Kudos I really appreci...      0   \n",
       "\n",
       "                                      new_description  \\\n",
       "0   ‚ô¶Ô∏è I wish you to stay healthi . your charact ,...   \n",
       "1      le base de l'algorithmiqu b darija vo remarqu    \n",
       "2   corona restrict caus terribl financi stress to...   \n",
       "3   üì£üì£amazon recrut de conseil client √† domicil .üßë...   \n",
       "4                                great illustr ... .    \n",
       "5   great to see compani across canada step up to ...   \n",
       "6                   Le maroc dont je sui si fier ...    \n",
       "7   hashtag # ÿπÿßÿ¨ŸÑ : ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸä...   \n",
       "8   I just publish the fourth and last blog post a...   \n",
       "9   the pain you feel today is the strength you fe...   \n",
       "10  ÿ£ŸàŸÑ ÿ¨Ÿáÿßÿ≤ ŸÖÿ≥ÿßÿπÿØÿ© ŸÑŸÑÿ™ŸÜŸÅÿ≥ ŸÖÿ∫ÿ±ÿ®Ÿä ŸÖÿ≠ŸÑŸä ÿßŸÑÿµŸÜÿπ . ŸÜÿ≠ÿ™ÿß...   \n",
       "11  are you at home practic social distanc to figh...   \n",
       "12  Ce viru a d√©voil√© une chose tr√® important pa a...   \n",
       "13  tout le mond est au courant sur le programm de...   \n",
       "14  kamal EL fatihi hashtag # kudo I realli apprec...   \n",
       "\n",
       "                                     new_description2  \n",
       "0     ‚ô¶Ô∏è wish stay healthi charact strength kind rest  \n",
       "1                 base algorithmiqu darija vo remarqu  \n",
       "2   corona restrict caus terribl financi stress po...  \n",
       "3   üì£üì£amazon recrut conseil client domicil üßë‚Äçüíªproc...  \n",
       "4                                       great illustr  \n",
       "5   great compani across canada step help fight co...  \n",
       "6                                      maroc sui fier  \n",
       "7   ÿπÿßÿ¨ŸÑ ŸÑŸÉŸÑ ŸÖŸÜ ŸäŸÖŸÉŸÜŸá ÿßŸÑŸÖÿ≥ÿßÿπÿØÿ© ŸÅŸä ÿ™ÿ£ŸÖŸäŸÜ ÿ£ÿ®ÿ≥ÿ∑ Ÿàÿ≥ÿßÿ¶ŸÑ...  \n",
       "8   publish fourth last blog post java featur thi ...  \n",
       "9   pain feel today strength feel tomorrowhashtag ...  \n",
       "10  ÿ£ŸàŸÑ ÿ¨Ÿáÿßÿ≤ ŸÖÿ≥ÿßÿπÿØÿ© ŸÑŸÑÿ™ŸÜŸÅÿ≥ ŸÖÿ∫ÿ±ÿ®Ÿä ŸÖÿ≠ŸÑŸä ÿßŸÑÿµŸÜÿπ ŸÜÿ≠ÿ™ÿßÿ¨ ...  \n",
       "11  home practic social distanc fight spread covid...  \n",
       "12  viru d√©voil√© chose tr√® important pa gen mai go...  \n",
       "13  mond courant programm coursera covid alor cr√©e...  \n",
       "14  kamal el fatihi kudo realli appreci goingabove...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['new_description2']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5639)\t0.31479550620807545\n",
      "  (0, 3580)\t0.4126273112969961\n",
      "  (0, 6337)\t0.3943569701348248\n",
      "  (0, 1018)\t0.3943569701348248\n",
      "  (0, 2912)\t0.3943569701348248\n",
      "  (0, 6298)\t0.3063150886474059\n",
      "  (0, 7124)\t0.4126273112969961\n",
      "  (1, 5539)\t0.5279037699843189\n",
      "  (1, 7000)\t0.3090066386266902\n",
      "  (1, 1613)\t0.5279037699843189\n",
      "  (1, 241)\t0.5279037699843189\n",
      "  (1, 650)\t0.2616633833643219\n",
      "  (2, 1669)\t0.16062438938320386\n",
      "  (2, 161)\t0.15118920975531885\n",
      "  (2, 3886)\t0.10379093434224992\n",
      "  (2, 7038)\t0.16062438938320386\n",
      "  (2, 2811)\t0.16062438938320386\n",
      "  (2, 2357)\t0.12095487368649681\n",
      "  (2, 2998)\t0.11373756348519617\n",
      "  (2, 4587)\t0.16062438938320386\n",
      "  (2, 5329)\t0.1444948432734052\n",
      "  (2, 4377)\t0.08393021217015281\n",
      "  (2, 6042)\t0.16062438938320386\n",
      "  (2, 4413)\t0.1444948432734052\n",
      "  (2, 2747)\t0.12836529716360653\n",
      "  :\t:\n",
      "  (730, 3424)\t0.04240867020843893\n",
      "  (730, 3427)\t0.04240867020843893\n",
      "  (730, 3431)\t0.04240867020843893\n",
      "  (730, 1721)\t0.08902020306892465\n",
      "  (730, 6364)\t0.058356818932424025\n",
      "  (730, 4993)\t0.056169088009404795\n",
      "  (730, 4085)\t0.061930083492763334\n",
      "  (730, 4033)\t0.06955931290853644\n",
      "  (730, 900)\t0.05151524115790386\n",
      "  (730, 3284)\t0.06097926622804786\n",
      "  (730, 3485)\t0.05646825185733726\n",
      "  (730, 1569)\t0.08972157299992302\n",
      "  (730, 2954)\t0.0722180244679133\n",
      "  (730, 6160)\t0.11799375389243666\n",
      "  (730, 3202)\t0.07879508112995981\n",
      "  (730, 5630)\t0.07675640911292379\n",
      "  (730, 314)\t0.10932090938116144\n",
      "  (730, 4515)\t0.19587678639501513\n",
      "  (730, 3913)\t0.18579025047828998\n",
      "  (730, 3222)\t0.1076088065539834\n",
      "  (730, 2739)\t0.06928331080238724\n",
      "  (730, 3757)\t0.06173650871962668\n",
      "  (730, 1248)\t0.0701222366186846\n",
      "  (730, 1583)\t0.051755579264469984\n",
      "  (730, 650)\t0.0731831445525845\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x= vectorizer.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#save tfidf \n",
    "pickle.dump(vectorizer,open(\"tfidf.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(976, 10040)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 10040)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test precision = 91.0%\n"
     ]
    }
   ],
   "source": [
    "testprecision = accuracy_score(pr, Y_test)\n",
    "print(\"test precision = {}%\".format(round(testprecision * 100),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = 'final_model.pkl'\n",
    "with open(my_model, 'wb') as file:  \n",
    "    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data20['description'] = data20['description'].apply(stemSentence)\n",
    "data20['description'] = data20['description'].apply(funct)\n",
    "\n",
    "tfidf_vectorizer = pickle.load(open(\"tfidf.pkl\", \"rb\"))\n",
    "new_dsc = tfidf_vectorizer.transform(data20['description'])\n",
    "print(type(data20['description']))\n",
    "\n",
    "my_model = 'final_model.pkl'\n",
    "with open(my_model, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "model.predict(new_dsc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
